{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9EJqf4T9a_1"
   },
   "source": [
    "# Image Categorizer: Deep Learning for Product Classification\n",
    "\n",
    "## Project Overview\n",
    "Welcome to the second project of Deep Learning College! ü•≥\n",
    "\n",
    "This project uses a dataset provided by [Torob](https://torob.com/), Iran's leading e-commerce search engine. Torob aggregates product information from various online stores into a single page, enabling users to easily find and compare products across different sellers.\n",
    "\n",
    "One of the most critical technical requirements for such a platform is the **automatic detection of product information**. Manual curation of this massive volume of data is extremely time-consuming and costly. **Product categorization** is arguably the most important information for searchability, playing a crucial role in the discoverability of products.\n",
    "\n",
    "In this project, we develop a deep learning model that can classify products based on their images, helping Torob automate this essential task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cs-csjvO9a_5"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Due to the dataset's large size (~270 MB), download it from [this link](https://drive.google.com/file/d/1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-/view?usp=sharing) and extract the files.\n",
    "\n",
    "**For Google Colab users**, download directly with:\n",
    "```python
    "!gdown 1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary><b>Troubleshooting gdown Download Issues</b></summary>\n",
    "\n",
    "If you encounter access permission errors with `gdown`, run this first:\n",
    "\n",
    "```python
    "!pip install --upgrade --no-cache-dir gdown\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "The dataset contains **11 product categories** with training images organized by category ID in the `train/` folder, and test images in the `test/` folder. Your model should predict the category for each test image.\n",
    "\n",
    "### Category Mapping\n",
    "\n",
    "| Category ID | Category Name |\n",
    "|-------------|---------------|\n",
    "| `0` | Men's Jackets, Raincoats, and Coats |\n",
    "| `1` | Men's Sweatshirts and Hoodies |\n",
    "| `2` | Analog and Digital Wristwatches |\n",
    "| `3` | Wall, Desk, and Decorative Clocks |\n",
    "| `4` | Accessories for Regular and Smart Watches |\n",
    "| `5` | Youth and Teen Sweatshirts and Hoodies |\n",
    "| `6` | Youth and Teen Jackets and Coats |\n",
    "| `7` | Men's Sports Sweatshirts |\n",
    "| `8` | Men's Sports Sweatshirt and Pants Sets |\n",
    "| `9` | Shopping Bags and Trolleys |\n",
    "| `10` | Suitcases and Travel Bags |\n",
    "\n",
    "**Next**: Load the dataset files and implement image loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Zzqq4eO9dOR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = df.sample(10)\n",
    "for i, row in sample.iterrows():\n",
    "    img = plt.imread(row['file_path'])\n",
    "    plt.title(f\"Label: {row['label']}\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHGMTg5I9a_7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkisYNAc9bAB"
   },
   "outputs": [],
   "source": [
    "# Reading/Loading the dataset files\n",
    "# TODO: Load training data and create DataFrame\n",
    "# Expected structure: columns 'file_path' and 'label'\n",
    "# Load all .jpg files from train/ directory, extract category from folder name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6eQYY5w9bAC"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Leverage any preprocessing techniques that you believe will improve model performance and training efficiency. Common techniques for this stage include:\n",
    "\n",
    "- **Image Resizing**: Standardizing input dimensions\n",
    "- **Normalization**: Scaling pixel values to [0,1] or [-1,1]\n",
    "- **Data Augmentation**: Rotation, flipping, zooming for robustness\n",
    "- **Pre-trained Model Preprocessing**: Specific preprocessing for the chosen backbone\n",
    "\n",
    "The goal is to prepare the data for optimal training while preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "You have complete freedom to design and experiment with your preferred architectures. Consider:\n",
    "\n",
    "**Option 1: Custom CNN**\n",
    "- Design from scratch using Conv2D, MaxPooling, BatchNorm, etc.\n",
    "- Apply techniques like residual connections, attention mechanisms\n",
    "\n",
    "**Option 2: Transfer Learning** *(Recommended)*\n",
    "- Use pre-trained backbones (ResNet, EfficientNet, MobileNet, etc.)\n",
    "- Decide which layers to freeze vs. fine-tune\n",
    "- Add custom classification head\n",
    "\n",
    "**Optimization Techniques**\n",
    "- Learning rate scheduling\n",
    "- Gradient clipping\n",
    "- Mixed precision training\n",
    "- Model checkpointing\n",
    "\n",
    "Don't forget to apply optimization and hyperparameter tuning techniques learned in previous chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSpKW0jJ9bAD"
   },
   "source": [
    "## Prediction & Evaluation\n",
    "\n",
    "The `test/` folder contains multiple test samples that your model needs to classify. We recommend first testing on a validation set to ensure model performance before final predictions.\n",
    "\n",
    "### Evaluation Metric\n",
    "The objective is to achieve **high accuracy** in product classification. Therefore, we use **Accuracy** as the primary evaluation metric.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Important:</b> To earn full credit, your solution must achieve at least <code>83</code> accuracy based on the specified metric.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "N6DahTSo9bAD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIR = './train'\n",
    "TEST_DIR = './test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)  # Image size reduction for faster processing\n",
    "BATCH_SIZE = 64  # Increased batch size for GPU efficiency\n",
    "EPOCHS = 20\n",
    "SEED = 123\n",
    "# --- 1. Prepare DataFrame for flow_from_dataframe ---\n",
    "file_paths = glob.glob(os.path.join(DATA_DIR, '*', '*.jpg'))\n",
    "data = {'file_path': [], 'label': []}\n",
    "for path in file_paths:\n",
    "    label = os.path.basename(os.path.dirname(path))\n",
    "    data['file_path'].append(path)\n",
    "    data['label'].append(label)\n",
    "df = pd.DataFrame(data)\n",
    "# Shuffle dataset for better training\n",
    "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].values\n",
    "classes = np.unique(labels)\n",
    "class_weights_values = compute_class_weight('balanced', classes=classes, y=labels)\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6178 validated image filenames belonging to 11 classes.\n",
      "Found 2647 validated image filenames belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    df, x_col='file_path', y_col='label',\n",
    "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', subset='training', shuffle=True, seed=SEED\n",
    ")\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    df, x_col='file_path', y_col='label',\n",
    "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', subset='validation', shuffle=False, seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# --- 4. Build Model ---\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    weights='./mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>\n"
     ]
    }
   ],
   "source": [
    "print(base_model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.3270 - loss: 2.6556 - val_accuracy: 0.5059 - val_loss: 1.8566 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.4949 - loss: 1.8913 - val_accuracy: 0.5519 - val_loss: 1.6973 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.5420 - loss: 1.6967 - val_accuracy: 0.5659 - val_loss: 1.5595 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.5694 - loss: 1.5811 - val_accuracy: 0.5731 - val_loss: 1.5615 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.5859 - loss: 1.4924 - val_accuracy: 0.5572 - val_loss: 1.5578 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.5797 - loss: 1.4954 - val_accuracy: 0.5841 - val_loss: 1.4549 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.6010 - loss: 1.4381 - val_accuracy: 0.6063 - val_loss: 1.4154 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.6043 - loss: 1.3943 - val_accuracy: 0.6018 - val_loss: 1.4231 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.5970 - loss: 1.4061 - val_accuracy: 0.5958 - val_loss: 1.4073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.6052 - loss: 1.3491 - val_accuracy: 0.6181 - val_loss: 1.3516 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.6095 - loss: 1.3488 - val_accuracy: 0.6154 - val_loss: 1.3445 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.6163 - loss: 1.3400 - val_accuracy: 0.5708 - val_loss: 1.4903 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.6209 - loss: 1.2978 - val_accuracy: 0.6188 - val_loss: 1.3209 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.6263 - loss: 1.3064 - val_accuracy: 0.6211 - val_loss: 1.3293 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.6283 - loss: 1.2926 - val_accuracy: 0.6305 - val_loss: 1.3003 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.6335 - loss: 1.2788 - val_accuracy: 0.6286 - val_loss: 1.2914 - learning_rate: 1.2500e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.6375 - loss: 1.2652 - val_accuracy: 0.6207 - val_loss: 1.3036 - learning_rate: 1.2500e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.6385 - loss: 1.2509 - val_accuracy: 0.6245 - val_loss: 1.2974 - learning_rate: 1.2500e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.6462 - loss: 1.2507 - val_accuracy: 0.6241 - val_loss: 1.3134 - learning_rate: 1.2500e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - accuracy: 0.6432 - loss: 1.2284 - val_accuracy: 0.6199 - val_loss: 1.3329 - learning_rate: 1.2500e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4734 - loss: 1.8252 - val_accuracy: 0.4322 - val_loss: 2.5444\n",
      "Epoch 2/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.6292 - loss: 1.2713 - val_accuracy: 0.4979 - val_loss: 2.0610\n",
      "Epoch 3/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.6357 - loss: 1.2482 - ...(truncated 86227 characters)...t matplotlib.pyplot as plt\n",
      "plt.figure(figsize=(12, 4))\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.plot(history.history['loss'] + fine_tune_history.history['loss'], label='Train Loss')\n",
      "plt.plot(history.history['val_loss'] + fine_tune_history.history['val_loss'], label='Val Loss')\n",
      "plt.title('Loss')\n",
      "plt.legend()\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.plot(history.history['accuracy'] + fine_tune_history.history['accuracy'], label='Train Accuracy')\n",
      "plt.plot(history.history['val_accuracy'] + fine_tune_history.history['val_accuracy'], label='Val Accuracy')\n",
      "plt.title('Accuracy')\n",
      "plt.legend()\n",
      "plt.show()"
     ]
    }
   ],
   "source": [
    "# Model training with comprehensive callbacks\n",
    "# This cell contains the complete training pipeline with:\n",
    "# - Initial training with frozen base model\n",
    "# - Progressive fine-tuning with learning rate scheduling\n",
    "# - Early stopping and learning rate reduction\n",
    "# - Mixed precision training for efficiency\n",
    "\n",
    "# Training configuration\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 10\n",
    "initial_learning_rate = 0.001\n",
    "fine_tune_learning_rate = 1e-5\n",
    "\n",
    "# Callbacks for training optimization\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Phase 1: Train classifier head with frozen base model\n",
    "print(\"=== Phase 1: Training Classifier Head ===\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=initial_epochs,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Phase 2: Fine-tuning with unfrozen base model layers\n",
    "print(\"\\n=== Phase 2: Fine-tuning Base Model ===\")\n",
    "\n",
    "# Unfreeze the top layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 30\n",
    "\n",
    "# Freeze all base model layers up to fine_tune_at\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=Adam(fine_tune_learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune_history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=fine_tune_epochs,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'] + fine_tune_history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'] + fine_tune_history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'] + fine_tune_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'] + fine_tune_history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Load test image paths\n",
    "test_files = glob.glob(os.path.join(TEST_DIR, '*.jpg'))\n",
    "test_df = pd.DataFrame({\n",
    "    'file_path': test_files,\n",
    "    'file': [os.path.basename(f).replace('.jpg', '') for f in test_files]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test\\-56lhw2AKjYI0Hnt.jpg</td>\n",
       "      <td>-56lhw2AKjYI0Hnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test\\-6OdHXCBItIArPyk.jpg</td>\n",
       "      <td>-6OdHXCBItIArPyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test\\-7241lsvPiVpNVFV.jpg</td>\n",
       "      <td>-7241lsvPiVpNVFV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test\\-8-0wltLEZBDTM5M.jpg</td>\n",
       "      <td>-8-0wltLEZBDTM5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test\\-dDdmvuCoHRNvJK-.jpg</td>\n",
       "      <td>-dDdmvuCoHRNvJK-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_path              file\n",
       "0  ./test\\-56lhw2AKjYI0Hnt.jpg  -56lhw2AKjYI0Hnt\n",
       "1  ./test\\-6OdHXCBItIArPyk.jpg  -6OdHXCBItIArPyk\n",
       "2  ./test\\-7241lsvPiVpNVFV.jpg  -7241lsvPiVpNVFV\n",
       "3  ./test\\-8-0wltLEZBDTM5M.jpg  -8-0wltLEZBDTM5M\n",
       "4  ./test\\-dDdmvuCoHRNvJK-.jpg  -dDdmvuCoHRNvJK-"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1201 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 503ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 2. Create test data generator (no labels)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input  # Fix preprocessing for EfficientNet\n",
    ")\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='file_path',\n",
    "    y_col=None,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 3. Generate model predictions\n",
    "preds = model.predict(test_gen, verbose=1)\n",
    "pred_indices = np.argmax(preds, axis=1)  # Get predicted class indices\n",
    "\n",
    "# 4. Map indices to correct labels\n",
    "# Class order from the problem: ['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "class_mapping = {\n",
    "    0: 0,   # Index 0 -> Label 0\n",
    "    1: 1,   # Index 1 -> Label 1\n",
    "    2: 10,  # Index 2 -> Label 10\n",
    "    3: 2,   # Index 3 -> Label 2\n",
    "    4: 3,   # Index 4 -> Label 3\n",
    "    5: 4,   # Index 5 -> Label 4\n",
    "    6: 5,   # Index 6 -> Label 5\n",
    "    7: 6,   # Index 7 -> Label 6\n",
    "    8: 7,   # Index 8 -> Label 7\n",
    "    9: 8,   # Index 9 -> Label 8\n",
    "    10: 9   # Index 10 -> Label 9\n",
    "}\n",
    "\n",
    "# Convert predicted indices to correct labels\n",
    "pred_labels = [class_mapping[idx] for idx in pred_indices]\n",
    "\n",
    "# 5. Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'image_name': test_df[\"file\"]+\".jpg\",  # Filename without extension\n",
    "    'cat_id': pred_labels           # Predicted category labels\n",
    "})\n",
    "\n",
    "# Save submission to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Generated submission.csv with {len(submission)} predictions\")\n",
    "print(f\"üìä Category distribution:\\n{submission['cat_id'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-56lhw2AKjYI0Hnt.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6OdHXCBItIArPyk.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7241lsvPiVpNVFV.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8-0wltLEZBDTM5M.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-dDdmvuCoHRNvJK-.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_name  cat_id\n",
       "0  -56lhw2AKjYI0Hnt.jpg       0\n",
       "1  -6OdHXCBItIArPyk.jpg       2\n",
       "2  -7241lsvPiVpNVFV.jpg       9\n",
       "3  -8-0wltLEZBDTM5M.jpg       9\n",
       "4  -dDdmvuCoHRNvJK-.jpg       9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_DUHsd69bAE"
   },
   "source": [
    "## Test Set Submission Format\n",
    "\n",
    "Generate predictions for test samples as category labels between 0-10 and store them in the `cat_id` column of a DataFrame named `submission` in the format shown below:\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `image_name` | Image filename (same as test sample) |\n",
    "| `cat_id` | Category ID/Label (model prediction) |\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>‚ö†Ô∏è Important:</b> When converting model outputs to labels, note that if you used `image_dataset_from_directory` for loading images, the class ordering will be alphabetical rather than numerical. The actual order will be:\n",
    "\n",
    "`['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']`\n",
    "\n",
    "This means the 3rd neuron output corresponds to label 10, not 2! Failing to account for this mapping is a common pitfall that causes good validation performance but poor test results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSD3SwaJ9bAE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# --- Mixed Precision Training ---\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# --- Config ---\n",
    "SEED = 123\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_PER_STAGE = 10\n",
    "DATA_DIR = './train'\n",
    "TEST_DIR = './test'\n",
    "\n",
    "# --- Load data ---\n",
    "file_paths = glob.glob(os.path.join(DATA_DIR, '*', '*.jpg'))\n",
    "data = {\n",
    "    'file_path': file_paths,\n",
    "    'label': [os.path.basename(os.path.dirname(p)) for p in file_paths]\n",
    "}\n",
    "df = pd.DataFrame(data).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# --- Class weights ---\n",
    "labels = df['label']\n",
    "classes = np.unique(labels)\n",
    "class_weights_arr = compute_class_weight('balanced', classes=classes, y=labels)\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_arr)}\n",
    "\n",
    "# --- Data generators ---\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=mobilenet_preprocess,\n",
    "    validation_split=0.3,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    df, x_col='file_path', y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    df, x_col='file_path', y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_gen.class_indices)\n",
    "\n",
    "# --- Build model ---\n",
    "def build_model(num_classes):\n",
    "    base = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "    base.trainable = False\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax', dtype='float32')(x)  # Important for mixed precision\n",
    "    return Model(inputs=base.input, outputs=output), base\n",
    "\n",
    "model, base_model = build_model(NUM_CLASSES)\n",
    "model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# --- Callbacks ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6)\n",
    "\n",
    "# --- Train (Phase 1: head training) ---\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS_PER_STAGE,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# --- Fine-tuning stages ---\n",
    "def fine_tune(model, base_model, train_gen, val_gen, freeze_until, lr, epochs):\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:freeze_until]:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[early_stop, reduce_lr]\n",
    "    )\n",
    "\n",
    "# Stage 2: Unfreeze last layers\n",
    "fine_tune(model, base_model, train_gen, val_gen, freeze_until=-30, lr=1e-4, epochs=EPOCHS_PER_STAGE)\n",
    "fine_tune(model, base_model, train_gen, val_gen, freeze_until=-70, lr=5e-5, epochs=EPOCHS_PER_STAGE)\n",
    "fine_tune(model, base_model, train_gen, val_gen, freeze_until=-100, lr=1e-5, epochs=EPOCHS_PER_STAGE)\n",
    "\n",
    "# --- Save final model ---\n",
    "model.save('final_model.keras')\n",
    "\n",
    "# --- Evaluate ---\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"\\nValidation Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "\n",
    "# --- Classification Report ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "val_gen.reset()\n",
    "preds = model.predict(val_gen)\n",
    "y_true = val_gen.classes\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Predict on test set ---\n",
    "test_files = glob.glob(os.path.join(TEST_DIR, '*.jpg'))\n",
    "test_df = pd.DataFrame({'file_path': test_files})\n",
    "test_gen = ImageDataGenerator(preprocessing_function=mobilenet_preprocess).flow_from_dataframe(\n",
    "    test_df, x_col='file_path', y_col=None,\n",
    "    target_size=IMG_SIZE,\n",
    "    class_mode=None,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_preds = model.predict(test_gen)\n",
    "predicted_labels = np.argmax(test_preds, axis=1)\n",
    "\n",
    "# Save results\n",
    "test_df['predicted_class'] = predicted_labels\n",
    "test_df.to_csv('test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MF05eyB9bAE"
   },
   "source": [
    "## Submission Generator\n",
    "\n",
    "To create the `result.zip` file, execute the cell below. **Important**: Save your notebook changes (`Ctrl+S`) before running this cell to ensure your code can be reviewed if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "beA07J9I9bAF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['image_categorizer.ipynb', 'submission.csv']\n",
      "\n",
      "‚úÖ Successfully created result.zip with submission files!\n",
      "üìÅ Files included:\n",
      "   ‚Ä¢ image_categorizer.ipynb (your solution code)\n",
      "   ‚Ä¢ submission.csv (model predictions)\n",
      "\n",
      "üéØ Ready for submission! Target accuracy: ‚â•83%\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "file_names = ['image_categorizer.ipynb', 'submission.csv']\n",
    "compress(file_names)\n",
    "\n",
    "print(\"\\n‚úÖ Successfully created result.zip with submission files!\")\n",
    "print(\"üìÅ Files included:\")\n",
    "for file in file_names:\n",
    "    print(f\"   ‚Ä¢ {file}\")\n",
    "print(\"\\nüéØ Ready for submission! Target accuracy: ‚â•83%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}